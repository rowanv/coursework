{
 "metadata": {
  "name": "",
  "signature": "sha256:17cd03cdd7d4beed6ede831831928880dccb43be70aa16444adfc1febdbc922c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: This tutorial used James et al.'s An Introduction to Statistical Learning with Applications in R as a reference. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook hand-codes a linear regression model. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.datasets import load_boston\n",
      "\n",
      "\n",
      "boston = load_boston()\n",
      "bos = pd.DataFrame(boston.data)\n",
      "bos.columns = boston.feature_names\n",
      "\n",
      "bos['price'] = boston.target\n",
      "bos.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>CRIM</th>\n",
        "      <th>ZN</th>\n",
        "      <th>INDUS</th>\n",
        "      <th>CHAS</th>\n",
        "      <th>NOX</th>\n",
        "      <th>RM</th>\n",
        "      <th>AGE</th>\n",
        "      <th>DIS</th>\n",
        "      <th>RAD</th>\n",
        "      <th>TAX</th>\n",
        "      <th>PTRATIO</th>\n",
        "      <th>B</th>\n",
        "      <th>LSTAT</th>\n",
        "      <th>price</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0.00632</td>\n",
        "      <td> 18</td>\n",
        "      <td> 2.31</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.538</td>\n",
        "      <td> 6.575</td>\n",
        "      <td> 65.2</td>\n",
        "      <td> 4.0900</td>\n",
        "      <td> 1</td>\n",
        "      <td> 296</td>\n",
        "      <td> 15.3</td>\n",
        "      <td> 396.90</td>\n",
        "      <td> 4.98</td>\n",
        "      <td> 24.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0.02731</td>\n",
        "      <td>  0</td>\n",
        "      <td> 7.07</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.469</td>\n",
        "      <td> 6.421</td>\n",
        "      <td> 78.9</td>\n",
        "      <td> 4.9671</td>\n",
        "      <td> 2</td>\n",
        "      <td> 242</td>\n",
        "      <td> 17.8</td>\n",
        "      <td> 396.90</td>\n",
        "      <td> 9.14</td>\n",
        "      <td> 21.6</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0.02729</td>\n",
        "      <td>  0</td>\n",
        "      <td> 7.07</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.469</td>\n",
        "      <td> 7.185</td>\n",
        "      <td> 61.1</td>\n",
        "      <td> 4.9671</td>\n",
        "      <td> 2</td>\n",
        "      <td> 242</td>\n",
        "      <td> 17.8</td>\n",
        "      <td> 392.83</td>\n",
        "      <td> 4.03</td>\n",
        "      <td> 34.7</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0.03237</td>\n",
        "      <td>  0</td>\n",
        "      <td> 2.18</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.458</td>\n",
        "      <td> 6.998</td>\n",
        "      <td> 45.8</td>\n",
        "      <td> 6.0622</td>\n",
        "      <td> 3</td>\n",
        "      <td> 222</td>\n",
        "      <td> 18.7</td>\n",
        "      <td> 394.63</td>\n",
        "      <td> 2.94</td>\n",
        "      <td> 33.4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.06905</td>\n",
        "      <td>  0</td>\n",
        "      <td> 2.18</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.458</td>\n",
        "      <td> 7.147</td>\n",
        "      <td> 54.2</td>\n",
        "      <td> 6.0622</td>\n",
        "      <td> 3</td>\n",
        "      <td> 222</td>\n",
        "      <td> 18.7</td>\n",
        "      <td> 396.90</td>\n",
        "      <td> 5.33</td>\n",
        "      <td> 36.2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "      CRIM  ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
        "0  0.00632  18   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
        "1  0.02731   0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
        "2  0.02729   0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
        "3  0.03237   0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
        "4  0.06905   0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
        "\n",
        "        B  LSTAT  price  \n",
        "0  396.90   4.98   24.0  \n",
        "1  396.90   9.14   21.6  \n",
        "2  392.83   4.03   34.7  \n",
        "3  394.63   2.94   33.4  \n",
        "4  396.90   5.33   36.2  "
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will approximate our predictor using the following equation:\n",
      "$$Y = \\beta_0 + \\beta_1X + \\epsilon $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Therefore, we aim to minimize the residual sum of least squares:\n",
      "$$RSS = e_1^2 + e_2^2 + ...+ e_n^2$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which for one independent variable can be rewritten as\n",
      "$$RSS = (y-\\beta_0 -\\beta_1X)^2$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to find values of $\\beta_0$ and $\\beta_1$ that minimize our equation, we want to know where the derivative of our equation will be equal to 0. Since this is a multivariate equation, we start by taking the derivative with respect to the regression constant:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\\frac{dRSS}{d\\beta_0} = \\frac{d}{d\\beta_0}[\\Sigma_{i=1}^{N}(y - \\beta_0 - \\beta_1X)^2]$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Since the derivative of the sums of an expression is equal to the sum of the expressions of the derivative, we can put the summation operator in front:\n",
      "    \n",
      "    $$\\frac{dRSS}{d\\beta_0} = \\Sigma_{i=1}^{N}\\frac{d}{d\\beta_0}[(y - \\beta_0 - \\beta_1X)^2]$$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}